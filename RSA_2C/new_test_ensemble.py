# Hieu Minh Truong modified
# -*- coding: utf-8 -*-
"""Copy of test_ensemble.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hXMlt5PAynYdps5D6DP1_q2eDtWyEIX5
"""

import os
import argparse
from typing import List

import numpy as np
import pandas as pd

from Bio import SeqIO

import torch
import torch.nn as nn
import matplotlib
from matplotlib import pyplot as plt
import seaborn as sns

from sklearn import metrics
from torch import optim
# from torch.utils.data import DataLoader

# from dataset.domainLinker_dataset import DomainLinkerDataset, Sequence, collate_fn
from dataset.utils import read_plm

from utils.common import dump_list2json, read_json2list

# HMT: Import pre-defined class, then later initialize the class
# with file paths provided in the call to this script
from params.filePath import paramF

import params.hyperparams_cbrcnn as paramH

import json

from model.utils import load_model, batch_acc, batch_auc
# from utils.static import type_dataset
from utils.ensemble import generate_models, ensemble_predict, ensemble_predict_new


"""# Functions"""

# 1. generate prediction label (not using)
def get_pred_label(pred, threshold=0.1):
    '''
    params:
        pred - predicted list
        label - ground truth
        threshold - better to set the threshold which make the precision similar to recall. (a higher F1 score.)
    return:
        pred_label - list, classification label generate from pred given threshold
    '''
    pred_label = [1 if i>threshold else 0 for i in pred]

    return pred_label

def get_idrIdx(pred_label):
    '''
    pdb atom index: _atom_site.label_seq_id (not author index)
    '''
    return [i+1 for i, e in enumerate(pred_label) if e == 1]

# 4. find index based on entity id
def get_idxByID(entity_id):
    for idx, entity in enumerate(list_test_entity):
        if entity_id==entity['id']:
            return idx

# HMT: Receive paths from the command line
parser = argparse.ArgumentParser()
parser.add_argument('-i', '--injson', required=True)
parser.add_argument('-o', '--outdir', required=True)
parser.add_argument('-m', '--mode', required=True, choices=['RSA_2C', 'RSA_4C', 'RSA_realValue'])
parser.add_argument('-p', '--outprefix')
args = parser.parse_args()

injson = args.injson
outdir = args.outdir
injson_base = os.path.splitext(os.path.basename(injson))[0]
if args.outprefix is not None:
    outprefix = args.outprefix
else:
    outprefix = injson_base
predmode = args.mode

# HMT: Read all the paths into the paramF object defined in params/filePath.py
path_collection = paramF(
        injson = injson,
        preddir = outdir,
        outprefix = outprefix,
        predmode = predmode
)


"""# 1. Predictors"""

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Using device:', device)

#esm&msa_transformer: https://github.com/facebookresearch/esm
featureType_list = ['onehot', 'protTrans', 'esm2']
featureType = featureType_list[2]
net_type = 'cbrcnn' # cbrcnn

netName = f'model.cbrcnn_stage1'
model_name = f'{netName[6:]}'

if featureType=='protTrans':
    n_features = 1024
elif featureType=='esm2':
    n_features = 1280
elif featureType=='onehot':
    n_features = 21

k_folds = 5

# HMT: get model dir path from the path_collection object (type: paramF)
folder_model =  os.path.join(path_collection.path_models, featureType)

list_modelInfo = [{'model_name':model_name, 'fold': f'_f{k}', 'net_name': netName, 'net_type': net_type, 'lr':paramH.lr, 'dropout':paramH.dropout, 'featureType': featureType, 'model_pth': os.path.join(folder_model, f'{model_name}_f{k}.pth')}  for k in range(1, 6)]
# HMT: add 'model_folder' argument to function call
models_P = generate_models(list_modelInfo, folder_model)


"""# 2. Prediction: Test set

## 2.1. dataset
"""

list_entity = read_json2list(injson)

"""## 2.2. prediction"""

# HMT: Name final solvent accessibility prediction file based on the provided prefix
path_pred_caid = os.path.join(outdir, predmode, f'{outprefix}.json')

# HMT: Provide path to the folder containing embedded features,
# organized into subfolders for each embedding method
features_dir = path_collection.path_features

list_predInfo = []
list_seq_id = []

for entity in list_entity:
    entity_id = entity['id']
    entity_length = entity['seq_len']

    # get prediction
    avg_pred = ensemble_predict_new(models_P, list_modelInfo, entity_id, features_dir, featureType, injson_base)

    predInfo = {'id': entity_id,  'seq_len': entity_length, 'true_pred': avg_pred.tolist()}
    list_predInfo.append(predInfo)
dump_list2json(list_predInfo, path_pred_caid)


"""## 2.3. evalution"""

# HMT: This seems incomplete. Comment out for now.
"""
from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve, f1_score, recall_score, precision_score, average_precision_score, roc_curve, auc

list_predInfo = read_json2list(path_pred_caid)

list_all_pred = []
for dict_pred in list_predInfo:
    list_all_pred.extend(dict_pred['true_pred'])
"""
